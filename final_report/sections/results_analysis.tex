\documentclass[final_report_innit.tex]{subfiles}

\begin{document}

\section{Results Analysis}

Small Introduction, one paragraph, hypothesis, which data was used, how it was analysed.

Demographics, who, how many, where, groupings

Explain what we measured, average, why things were taken out (how we decided that).

State any direct correlations or evidence that supports our hypothesis.

Present the results in a table

P - Performance
Q - Quality of what you deliver
PF - Personal Fulfilment
EOI - Ease of Implementation

\section{Discussion}

Intro to discussion, process then design, why.



FD/OT - MDSD seems to prefer it as it creates less merge conflicts, MC, seem to dislike it, which is weird. Discuss this. Jesper agrees this is weird. Suggest here more study is required, we don't have enough information. They scored it low in ease of implementation, perhaps this is an indicator.

CF - Positive, considered finished and implemented. 

CI - Both positive, same result. Only process which is considered finished. Results seem to show high acceptance of this or liking of it.

\subsection*{Process}

\subsection*{Design}

Component testing and Unit testing have been a staple of the design process at Ericsson for quite some time. Given this, we expected there to be an overall trend of positivity towards both in the organisation. On average however, the results showed that the response was, in fact, rather different. The MDSD developers were a little more negative, averaging total scores of 2.6 for unit testing and 3.4 for component testing. MC developers had a more favorable opinion of them, they were scored 3.6 and 3.7 respectively. We found this surprising as we expected the manual coders to score higher than the MDSD developers. Our opinion was that modelling tests, specifically unit tests, would be harder to do than writing them manually in code. This was mainly because we felt that the existence of large, tried and tested frameworks would hopefully ease the implementation of tests. Further interesting results was the large disparity in regards to ease of implementation. In both types of testing, the MDSD groups rated the ease of implementation to be far lower than their manual coding counterparts who gave them a 3.5 and 3.3 respectively. This was something that we thought would probably be true, purely based from personal experiences.

*It's worth noting that we have no experience with testing in a MDSD environment and a such we had no opinions to drawn upon. This was also evident in research, as we were able to find the existence of frameworks and suggestions, but there was nothing which gave us an indication that it was any easier, or harder than manual unit testing.*

Our interviewee had a different opinion. They suggested thought that the MDSD teams would actually hold the testing in higher regard than the manual coders. The reasoning for this was that, \textit{``when MDSD was first introduced many new people came onto the teams who had specific knowledge and expertise with using MDSD''}. These experts would have been well versed in the art of creating tests for use in MDSD as they have always had to do them so would have no real reason to dislike them. It was expressed that the MDSD developers have had much more experience in writing unit tests than the manual coders. Specifically, the interviewee mentioned that \textit{``Manual side, they, typically and historically speaking have had neither unit or component testing''}. The interviewee also expressed an opinion that the MDSD developers probably prefer Component testing rather than unit testing. This might have meant that they had given them an \textit{``unfair score''}. Interestingly the interviewee mentioned that the MDSD teams are currently moving away from Unit testing and this could be a reason for their apparent dislike of it.

During the interview process at Ericsson, it became clear that the manual coders do not see a distinction between the two types of
testing that are currently performed; those are Unit testing and Component testing. This was reinforced by the interviewee who mentioned that \textit{``From a knowledge point of view, they don't equate the two''}. We feel that this could have contributed significantly to the disparity between the two groups, but ultimately, our limited and inadequate data set means that we cannot make assumptions with any certainty.

\subsection*{Limitations}

Sample Size
Ordinality of the questions, ref to paper, counter with the fact that we have mean etc

Control over distribution
We had no control over the recipients of the surveys; they were handed out for us via Jesper.

Reference the paper where this was found!!

We had one interview which limits the responses as we have nothing else to compare the answers with.

EPG - We only looked at one subset of Ericsson.

\subsection*{Recomendations (To Ericsson according to CM)}

*Perhaps include a recomendation for comparing MDSD vs CM

\end{document}